{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理实战 —— 文本分类\n",
    "\n",
    "文本分类是自然语言处理（NLP）领域的重要研究领域。文本分类指将文本按照一定的分类体系或标准进行分类标记，包括二分类和多分类等。在人工智能浪潮席卷全球的今天，文本分类技术已经被广泛地应用在情感分析、文本审核、广告过滤和反黄识别等 NLP 领域。现阶段的文本分类模型种类繁多，既有机器学习中的朴素贝叶斯模型、SVM 等，也有深度学习中的各种模型，比如经典的 CNN、RNN，以及它们的变形，如 CNN-LSTM 等。\n",
    "\n",
    "本实践首先介绍 ModelArts 的文本分类功能，之后使用 BERT 模型进行文本分类任务——中文文本情感分析。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelArts 文本分类功能\n",
    "\n",
    "本部分将介绍通过 ModelArts 的文本分类标注功能：对文本的内容按照标签进行分类处理。\n",
    "\n",
    "登录 ModelArts 管理控制台，在左侧菜单栏中选择`数据标注`，进入`数据集`管理页面。\n",
    "\n",
    "点击`创建数据集`，准备用于数据标注的文本数据。\n",
    "\n",
    "![](./img/data_tagging.png)\n",
    "\n",
    "#### 准备未标注数据集\n",
    "\n",
    "首先需要在 OBS 中创建一个数据集，后续的操作如标注数据、数据集发布等，都是基于创建和管理的数据集。\n",
    "\n",
    "OBS 链接在这里：https://www.huaweicloud.com/product/obs0.html\n",
    "\n",
    "数据标注功能需要获取访问 OBS 权限，在未进行委托授权之前，无法使用此功能。需要可以在`数据标注`页面，单击`服务授权`，由具备授权的账号`同意授权`后，即可使用。\n",
    "\n",
    "创建用于存储数据的 OBS 桶及文件夹。本实践中桶名设定为`classification-tagging`，**请用户建立新桶并自定义命名，OBS桶名全局唯一，若创建时桶名冲突，请选择其他不冲突桶名**。\n",
    "\n",
    "桶创建成功后，在桶中创建标注输入和标注输出的文件夹，并将用于标注是文本文件上传到输入文件夹中。\n",
    "\n",
    "文本标注文件的要求为：**文件格式要求 txt 或者 csv，文件大小不超过 8M，以换行符作为分隔符，每行数据代表一个标注对象。**\n",
    "\n",
    "在本实践中使用的示例标注文件`text.txt`可以[点此下载](https://modelarts-labs.obs.cn-north-1.myhuaweicloud.com/notebook/DL_nlp_text_classification/text.tar.gz)，解压后可上传到输入文件夹中按照本案例步骤使用。\n",
    "\n",
    "在本实践中创建文件夹结构示例如下：\n",
    "\n",
    "```\n",
    "tagging\n",
    "   │\n",
    "   ├─input\n",
    "   │       └─text.txt\n",
    "   └─output\n",
    "```\n",
    "\n",
    "其中\n",
    "\n",
    "- `input`   为文本分类输入文件夹\n",
    "- `text.txt`   为文本分类输入文本文件\n",
    "- `output`   为文本分类输出文件夹\n",
    "\n",
    "\n",
    "创建文本分类任务数据集，如下图所示\n",
    "\n",
    "![](./img/tagging_classification_1.png)\n",
    "\n",
    "注意创建参数\n",
    "\n",
    "- 名称：可自定义数据集名称，本案例中设定为`classification-tagging`\n",
    "- 数据集输入位置：本案例中设定为`/classification-tagging/tagging/input/`\n",
    "- 数据集输出位置：本案例中设定为`/classification-tagging/tagging/output/`\n",
    "- 标注场景：选择`文本`\n",
    "- 标注类型：选择`文本分类`\n",
    "- 添加标签集：可自定义标签名称、个数、颜色。本案例中设定两个分类标签：`正面`标签为红色；`负面`标签为绿色。\n",
    "\n",
    "![](./img/label_color.png)\n",
    "\n",
    "完成以上设定后，点击右下角`创建`。文本分类数据集创建完成后，系统自动跳转至数据集管理页面。\n",
    "\n",
    "![](./img/tagging_classification_2.png)\n",
    "\n",
    "点击数据集名称，进入标注界面。选择未标注对象，点击标签进行标注，如图所示\n",
    "\n",
    "![](./img/tagging_classification_3.png)\n",
    "\n",
    "选择标注对象：`那场比赛易建联打得真好！`，从标签集选择`正面`标签，然后点击下方`保存当前页`进行保存。\n",
    "\n",
    "继续选择其他标注对象，按上述方法进行标注。数据全部标注完成后（本样例中仅提供五条分类文本），点击`已标注`可查看标注结果。\n",
    "\n",
    "![](./img/tagging_classification_4.png)\n",
    "\n",
    "点击`返回数据集`，可以看到数据集已全部标注成功。\n",
    "\n",
    "![](./img/tagging_classification_5.png)\n",
    "\n",
    "针对刚创建的数据集（未发布前），无数据集版本信息，必须执行发布操作后，才能应用于模型开发或训练。\n",
    "\n",
    "点击`发布`，可以编辑版本名称，本案例中为默认`V001`。\n",
    "\n",
    "![](./img/tagging_classification_6.png)\n",
    "\n",
    "发布成功如图所示。\n",
    "\n",
    "![](./img/tagging_classification_7.png)\n",
    "\n",
    "可以查看数据集版本的 “名称”、 “状态”、 “文件总数”、 “已标注文件个数”，并在左侧的 “演进过程”中查看版本的发布时间。\n",
    "\n",
    "随后可以使用标注成功的数据集，标注结果储存在`output`文件夹中。\n",
    "\n",
    "后续 ModelArts 将会上线智能标注功能，相信大家已经体验过第二期实战的图像智能标注，能够快速完成数据标注，节省70%以上的标注时间。智能标注是指基于当前标注阶段的标签及学习训练，选中系统中已有的模型进行智能标注，快速完成剩余数据的标注操作。请持续关注数据标注功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进入ModelArts\n",
    "\n",
    "点击如下链接：https://www.huaweicloud.com/product/modelarts.html ， 进入ModelArts主页。点击“立即使用”按钮，输入用户名和密码登录，进入ModelArts使用页面。\n",
    "\n",
    "### 创建ModelArts notebook\n",
    "\n",
    "下面，我们在ModelArts中创建一个notebook开发环境，ModelArts notebook提供网页版的Python开发环境，可以方便的编写、运行代码，并查看运行结果。\n",
    "\n",
    "第一步：在ModelArts服务主界面依次点击“开发环境”、“创建”\n",
    "\n",
    "![create_nb_create_button](./img/create_nb_create_button.png)\n",
    "\n",
    "第二步：填写notebook所需的参数：\n",
    "\n",
    "| 参数 | 说明 |\n",
    "| - - - - - | - - - - - |\n",
    "| 计费方式 | 按需计费  |\n",
    "| 名称 | Notebook实例名称，如 text_sentiment_analysis |\n",
    "| 工作环境 | Python3 |\n",
    "| 资源池 | 选择\"公共资源池\"即可 |\n",
    "| 类型 | 本案例使用较为复杂的深度神经网络模型，需要较高算力，选择\"GPU\" |\n",
    "| 规格 | 选择\"8核 &#124; 64GiB &#124; 1*p100\" |\n",
    "| 存储配置 | 选择EVS，磁盘规格5GB |\n",
    "\n",
    "第三步：配置好notebook参数后，点击下一步，进入notebook信息预览。确认无误后，点击“立即创建”\n",
    "\n",
    "![create_nb_creation_summary](./img/create_nb_creation_summary.png)\n",
    "\n",
    "第四步：创建完成后，返回开发环境主界面，等待Notebook创建完毕后，打开Notebook，进行下一步操作。\n",
    "![modelarts_notebook_index](./img/modelarts_notebook_index.png)\n",
    "\n",
    "### 在ModelArts中创建开发环境\n",
    "\n",
    "接下来，我们创建一个实际的开发环境，用于后续的实验步骤。\n",
    "\n",
    "第一步：点击下图所示的“打开”按钮，进入刚刚创建的Notebook\n",
    "![inter_dev_env](img/enter_dev_env.png)\n",
    "\n",
    "第二步：创建一个Python3环境的的Notebook。点击右上角的\"New\"，然后创建TensorFlow 1.13.1开发环境。\n",
    "\n",
    "第三步：点击左上方的文件名\"Untitled\"，并输入一个与本实验相关的名称\n",
    "![notebook_untitled_filename](./img/notebook_untitled_filename.png)\n",
    "![notebook_name_the_ipynb](./img/notebook_name_the_ipynb.png)\n",
    "\n",
    "\n",
    "### 在Notebook中编写并执行代码\n",
    "\n",
    "在Notebook中，我们输入一个简单的打印语句，然后点击上方的运行按钮，可以查看语句执行的结果：\n",
    "![run_helloworld](./img/run_helloworld.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分类——中文文本情感分析\n",
    "\n",
    "文本情感分析是指对带有主观性的观点、喜好、情感等文本进行分析和挖掘。最初的文本情感分析来自对带有情感色彩的词语的分析，例如，“美好”是带有褒义色彩的词语，而“丑陋”是带有贬义色彩的词语。随着互联网上大量的带有情感色彩的主观性文本的出现，研究者们逐渐从简单的情感词语的分析研究扩展到更为复杂的完整情感文本的研究。\n",
    "\n",
    "为了定量表示情感偏向，一般使用0到1之间的一个浮点数给文本打上情感标签，越接近1表示文本的情感越正向，越接近0表示情感越负向。\n",
    "\n",
    "### 数据集\n",
    "\n",
    "在本实战中，使用的中文文本分类的数据集来自谭松波老师从某酒店网站上整理的酒店评论数据。数据集共7000多条评论数据，5000多条正向评论，2000多条负向评论。\n",
    "\n",
    "数据格式：\n",
    "\n",
    "| 字段 | label  | review     | \n",
    "| ---- | ------- | ---------- | \n",
    "| 含义 | 情感标签  | 评论文本 |\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "### BERT 模型\n",
    "\n",
    "本实践使用 NLP 领域最新最强大的 **BERT** 模型。\n",
    "\n",
    "中文**BERT-Base,Chinese**预训练模型，可以从链接[BERT-Base, Chinese](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip)下载使用。\n",
    "\n",
    "#### 准备源代码和数据\n",
    "\n",
    "准备案例所需的源代码和数据，相关资源已经保存在 OBS 中，我们通过 ModelArts SDK 将资源下载到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file modelarts-labs/notebook/DL_nlp_text_classification/text_classification.tar.gz from OBS to local ./text_classification.tar.gz\n",
      "total 374440\r\n",
      "drwxrwxrwx  4 ma-user ma-group      4096 Sep 11 18:11 .\r\n",
      "drwsrwsr-x 22 ma-user ma-group      4096 Sep 11 15:14 ..\r\n",
      "drwxr-x---  2 ma-user ma-group      4096 Sep 11 15:01 .ipynb_checkpoints\r\n",
      "-rw-r-----  1 ma-user ma-group     34407 Sep 11 18:11 text_classification.ipynb\r\n",
      "-rw-r-----  1 ma-user ma-group 383370868 Sep 11 18:11 text_classification.tar.gz\r\n",
      "drwx------  2 ma-user ma-group      4096 Sep 11 18:07 .Trash-1000\r\n"
     ]
    }
   ],
   "source": [
    "from modelarts.session import Session\n",
    "session = Session()\n",
    "\n",
    "if session.region_name == 'cn-north-1':\n",
    "    bucket_path = 'modelarts-labs/notebook/DL_nlp_text_classification/text_classification.tar.gz'\n",
    "    \n",
    "elif session.region_name == 'cn-north-4':\n",
    "    bucket_path = 'modelarts-labs-bj4/notebook/DL_nlp_text_classification/text_classification.tar.gz'\n",
    "else:\n",
    "    print(\"请更换地区到北京一或北京四\")\n",
    "    \n",
    "session.download_data(bucket_path=bucket_path, path='./text_classification.tar.gz')\n",
    "\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压从obs下载的压缩包，解压后删除压缩包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56\r\n",
      "drwxrwxrwx  5 ma-user ma-group  4096 Sep 11 18:11 .\r\n",
      "drwsrwsr-x 22 ma-user ma-group  4096 Sep 11 15:14 ..\r\n",
      "drwxr-x---  2 ma-user ma-group  4096 Sep 11 15:01 .ipynb_checkpoints\r\n",
      "drwxr-x---  6 ma-user ma-group  4096 Sep 11 11:28 text_classification\r\n",
      "-rw-r-----  1 ma-user ma-group 34407 Sep 11 18:11 text_classification.ipynb\r\n",
      "drwx------  2 ma-user ma-group  4096 Sep 11 18:07 .Trash-1000\r\n"
     ]
    }
   ],
   "source": [
    "!tar xf ./text_classification.tar.gz\n",
    "\n",
    "!rm ./text_classification.tar.gz\n",
    "\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "升级tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow==1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow-gpu==1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.11.0\n",
    "\n",
    "!pip install tensorflow-gpu==1.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from text_classification.bert import modeling, optimization, tokenization\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义数据和模型路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './text_classification/data/'\n",
    "output_dir = './text_classification/output/'\n",
    "vocab_file = './text_classification/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "bert_config_file = './text_classification/chinese_L-12_H-768_A-12/bert_config.json'\n",
    "init_checkpoint = './text_classification/chinese_L-12_H-768_A-12/bert_model.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "learning_rate = 2e-5 \n",
    "num_train_epochs = 3 \n",
    "warmup_proportion = 0.1\n",
    "save_checkpoints_steps = 500 \n",
    "save_summary_steps = 100 \n",
    "max_seq_length = 128\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据集\n",
    "\n",
    "需要获取非倾斜的数据集，使标签的比例基本相等。\n",
    "\n",
    "随机展示训练集样本20条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总评论数：4000\n",
      "正向评论：2000\n",
      "负向评论：2000\n",
      "\n",
      "训练样本示例\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>0</td>\n",
       "      <td>我那天用信用卡作了担保，订26号凌晨的大床房，事先说明了入住的时间的。结果，到达酒店的时候，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>1</td>\n",
       "      <td>物有所值,但其预定车票的服务太一般,我给他们商务中心要求订次日到西安的卧铺票,除要收我30元...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>0</td>\n",
       "      <td>房内设施简陋,客人很少,很冷清,很没落,没有象样的温泉,早餐是有人吃才开火,而且什么都没有,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>0</td>\n",
       "      <td>我订的行政房，房间很小，而且楼比较旧，除了能上网没觉得跟普标有什么差别。酒店本身也很小。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>0</td>\n",
       "      <td>对于酒店的服务态度基本满意,唯一缺陷就是没有遵守时间.我提前1小时和酒店总台确认过了我到达浦...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>1</td>\n",
       "      <td>交通方便，搭机场快线香港站出来坐H1直达，步行到地铁站5分钟，门口就有叮叮车；房间虽小，但干...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>0</td>\n",
       "      <td>前台接待太差，酒店有AB楼之分，本人check－in后，前台未告诉B楼在何处，并且B楼无明显...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>0</td>\n",
       "      <td>在汕尾的酒店不多(上档次的),只能订这个了.如果可以的话,去海丰住比在汕尾住好多了^^酒店不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>1</td>\n",
       "      <td>２００１年来福州就住在这里，这次感觉房间就了点，温泉水还是有的．总的来说很满意．早餐简单了些．</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>1</td>\n",
       "      <td>地理位置较优越，房间内干净整洁，不能说很安静但出门在外凡事不能太叫真，隔音还是可以的，可以考...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1</td>\n",
       "      <td>每次去河南基本上都住这家酒店,环境设施都不错,房间宽敞,服务也好!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>1</td>\n",
       "      <td>诺覃祥渣,厄珩祥渣,憩苌腔Ⅰ耋剩.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1</td>\n",
       "      <td>房间以及环境都不错，用房卡到四楼的五指生足部保健还可以打折。就是退房时速度有点慢！免费注册网...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>0</td>\n",
       "      <td>入住感想如下、供参考。1、离机场很近、无车接送、走路约八分钟。夜晚、雨天走路艰难。2、谈不上...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>1</td>\n",
       "      <td>如果为了购物，地段绝对好。但是，毕竟是闹市区稍微有点吵难免的。补充点评2008年4月1日：今...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>1</td>\n",
       "      <td>前台服务态度很好很细心，但是硬件设施由于跟不上，老化。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>1</td>\n",
       "      <td>服务稍微差一点，入住后房间打扫不彻底，床单不能每天更换。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>1</td>\n",
       "      <td>酒店环境和服务都还不错，地理位置也不错，尤其是酒店北面的川北凉粉确实好吃，不过就是隔音效果不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>第一次入住，感觉酒店很华丽，房间也还不错。不过枕头太多了，不知道放那么多是干什么用的。服务感...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>1</td>\n",
       "      <td>应该是亦庄经济技术开发区最好的酒店了，交通便利，环境安静。只是房间比较小，前台服务态度一般。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "7122      0  我那天用信用卡作了担保，订26号凌晨的大床房，事先说明了入住的时间的。结果，到达酒店的时候，...\n",
       "4630      1  物有所值,但其预定车票的服务太一般,我给他们商务中心要求订次日到西安的卧铺票,除要收我30元...\n",
       "6345      0  房内设施简陋,客人很少,很冷清,很没落,没有象样的温泉,早餐是有人吃才开火,而且什么都没有,...\n",
       "7297      0       我订的行政房，房间很小，而且楼比较旧，除了能上网没觉得跟普标有什么差别。酒店本身也很小。\n",
       "7028      0  对于酒店的服务态度基本满意,唯一缺陷就是没有遵守时间.我提前1小时和酒店总台确认过了我到达浦...\n",
       "5196      1  交通方便，搭机场快线香港站出来坐H1直达，步行到地铁站5分钟，门口就有叮叮车；房间虽小，但干...\n",
       "5603      0  前台接待太差，酒店有AB楼之分，本人check－in后，前台未告诉B楼在何处，并且B楼无明显...\n",
       "6560      0  在汕尾的酒店不多(上档次的),只能订这个了.如果可以的话,去海丰住比在汕尾住好多了^^酒店不...\n",
       "3967      1    ２００１年来福州就住在这里，这次感觉房间就了点，温泉水还是有的．总的来说很满意．早餐简单了些．\n",
       "2850      1  地理位置较优越，房间内干净整洁，不能说很安静但出门在外凡事不能太叫真，隔音还是可以的，可以考...\n",
       "1421      1                  每次去河南基本上都住这家酒店,环境设施都不错,房间宽敞,服务也好!\n",
       "4572      1                                  诺覃祥渣,厄珩祥渣,憩苌腔Ⅰ耋剩.\n",
       "1314      1  房间以及环境都不错，用房卡到四楼的五指生足部保健还可以打折。就是退房时速度有点慢！免费注册网...\n",
       "7590      0  入住感想如下、供参考。1、离机场很近、无车接送、走路约八分钟。夜晚、雨天走路艰难。2、谈不上...\n",
       "2739      1  如果为了购物，地段绝对好。但是，毕竟是闹市区稍微有点吵难免的。补充点评2008年4月1日：今...\n",
       "5080      1                        前台服务态度很好很细心，但是硬件设施由于跟不上，老化。\n",
       "4522      1                       服务稍微差一点，入住后房间打扫不彻底，床单不能每天更换。\n",
       "4805      1  酒店环境和服务都还不错，地理位置也不错，尤其是酒店北面的川北凉粉确实好吃，不过就是隔音效果不...\n",
       "4073      1  第一次入住，感觉酒店很华丽，房间也还不错。不过枕头太多了，不知道放那么多是干什么用的。服务感...\n",
       "2313      1     应该是亦庄经济技术开发区最好的酒店了，交通便利，环境安静。只是房间比较小，前台服务态度一般。"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_balance_corpus(corpus_size, corpus_pos, corpus_neg):\n",
    "    sample_size = corpus_size // 2\n",
    "    pd_corpus_balance = pd.concat([corpus_pos.sample(sample_size, replace=corpus_pos.shape[0]<sample_size), \\\n",
    "                                   corpus_neg.sample(sample_size, replace=corpus_neg.shape[0]<sample_size)])\n",
    "    \n",
    "    print('总评论数：%d' % pd_corpus_balance.shape[0])\n",
    "    print('正向评论：%d' % pd_corpus_balance[pd_corpus_balance.label==1].shape[0])\n",
    "    print('负向评论：%d' % pd_corpus_balance[pd_corpus_balance.label==0].shape[0])    \n",
    "    \n",
    "    return pd_corpus_balance\n",
    "\n",
    "reviews_all = pd.read_csv(data_dir + 'ChnSentiCorp_htl_all.csv')\n",
    "\n",
    "pd_positive = reviews_all[reviews_all.label==1]\n",
    "pd_negative = reviews_all[reviews_all.label==0]\n",
    "\n",
    "reviews_4000 = get_balance_corpus(4000, pd_positive, pd_negative)\n",
    "\n",
    "train, test = train_test_split(reviews_4000, test_size=0.2)\n",
    "\n",
    "print('\\n训练样本示例\\n')\n",
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取BERT预训练模型中文字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今', '天', '的', '天', '气', '真', '好', '！']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=False)\n",
    "\n",
    "tokenizer.tokenize(\"今天的天气真好！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建数据输入类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "\n",
    "    def __init__(self,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               label_id,\n",
    "               is_real_example=True):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.is_real_example = is_real_example\n",
    "    \n",
    "class PaddingInputExample(object):\n",
    "    pass\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'label'\n",
    "\n",
    "train_InputExamples = train.apply(lambda x: InputExample(guid=None,  \n",
    "                                                         text_a = x[DATA_COLUMN], \n",
    "                                                         text_b = None, \n",
    "                                                         label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: InputExample(guid=None, \n",
    "                                                       text_a = x[DATA_COLUMN], \n",
    "                                                       text_b = None, \n",
    "                                                       label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换为 BERT 输入向量\n",
    "\n",
    "打印前5个样例文本及其字向量、文本向量、位置向量和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 3200\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 酒 店 软 硬 件 都 不 错 ， 游 泳 池 更 不 错 。 只 是 周 围 没 有 吃 饭 的 地 方 ， 一 定 到 打 车 出 去 。 另 外 ， 酒 店 不 让 出 租 车 在 酒 店 门 口 待 客 ， 客 人 要 走 到 马 路 上 打 车 ， 是 法 国 人 的 新 招 吗 ？ 同 酒 店 服 务 的 档 次 严 重 脱 位 。 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 6983 2421 6763 4801 816 6963 679 7231 8024 3952 3807 3737 3291 679 7231 511 1372 3221 1453 1741 3766 3300 1391 7649 4638 1765 3175 8024 671 2137 1168 2802 6756 1139 1343 511 1369 1912 8024 6983 2421 679 6375 1139 4909 6756 1762 6983 2421 7305 1366 2521 2145 8024 2145 782 6206 6624 1168 7716 6662 677 2802 6756 8024 3221 3791 1744 782 4638 3173 2875 1408 8043 1398 6983 2421 3302 1218 4638 3440 3613 698 7028 5564 855 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 房 间 里 铺 着 像 餐 馆 一 样 的 廉 价 石 砖 地 ， 两 床 之 间 有 一 块 肮 脏 的 地 毯 床 上 只 有 及 薄 的 褥 子 ， 床 垫 上 的 弹 簧 不 分 轻 重 的 时 刻 [UNK] 着 你 。 喷 头 出 的 水 永 远 只 有 两 种 温 度 ， 极 热 和 极 冷 出 行 不 方 便 ， 地 点 比 较 偏 颇 ， 从 解 放 碑 打 车 ， 很 多 司 机 都 不 去 。 总 之 糟 糕 透 顶 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2791 7313 7027 7215 4708 1008 7623 7667 671 3416 4638 2442 817 4767 4778 1765 8024 697 2414 722 7313 3300 671 1779 5506 5552 4638 1765 3691 2414 677 1372 3300 1350 5946 4638 6191 2094 8024 2414 1807 677 4638 2486 5082 679 1146 6768 7028 4638 3198 1174 100 4708 872 511 1613 1928 1139 4638 3717 3719 6823 1372 3300 697 4905 3946 2428 8024 3353 4178 1469 3353 1107 1139 6121 679 3175 912 8024 1765 4157 3683 6772 974 7567 8024 794 6237 3123 4811 2802 6756 8024 2523 1914 1385 3322 6963 679 1343 511 2600 722 5136 5130 6851 7553 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 酒 店 服 务 态 度 极 差 ， 设 施 很 差 ， 建 议 还 是 不 要 到 那 儿 去 。 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 6983 2421 3302 1218 2578 2428 3353 2345 8024 6392 3177 2523 2345 8024 2456 6379 6820 3221 679 6206 1168 6929 1036 1343 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 入 住 酒 店 , 被 告 知 大 床 房 客 人 未 退 , 给 我 免 费 \" 升 级 \" 成 标 间 , 可 惜 我 是 和 爱 人 一 起 来 的 , 不 是 出 差 , 哎 , 有 点 失 望 . 不 过 酒 店 位 置 不 错 , 这 几 天 边 上 修 路 , 但 路 面 用 塑 料 薄 膜 覆 盖 , 无 扬 灰 , 无 太 大 影 响 , 房 间 安 静 , 房 间 内 部 装 饰 细 节 等 不 错 . 工 作 人 员 服 务 态 度 好 , 表 扬 . 房 间 热 水 器 不 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1057 857 6983 2421 117 6158 1440 4761 1920 2414 2791 2145 782 3313 6842 117 5314 2769 1048 6589 107 1285 5277 107 2768 3403 7313 117 1377 2667 2769 3221 1469 4263 782 671 6629 3341 4638 117 679 3221 1139 2345 117 1511 117 3300 4157 1927 3307 119 679 6814 6983 2421 855 5390 679 7231 117 6821 1126 1921 6804 677 934 6662 117 852 6662 7481 4500 1848 3160 5946 5606 6208 4667 117 3187 2813 4129 117 3187 1922 1920 2512 1510 117 2791 7313 2128 7474 117 2791 7313 1079 6956 6163 7652 5301 5688 5023 679 7231 119 2339 868 782 1447 3302 1218 2578 2428 1962 117 6134 2813 119 2791 7313 4178 3717 1690 679 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 10 多 年 来 住 过 的 近 百 家 3 星 酒 店 中 ， 这 家 酒 店 的 服 务 、 房 间 、 餐 饮 简 直 是 [UNK] 好 [UNK] 的 无 话 可 说 ！ ！ ！ 向 大 堂 经 理 反 映 问 题 ， 大 堂 经 理 的 答 复 是 [UNK] 去 315 投 诉 吧 [UNK] （ 入 住 当 天 是 3 月 12 日 ） ， 真 强 悍 ！ ！ ！ [SEP]\n",
      "INFO:tensorflow:input_ids: 101 8108 1914 2399 3341 857 6814 4638 6818 4636 2157 124 3215 6983 2421 704 8024 6821 2157 6983 2421 4638 3302 1218 510 2791 7313 510 7623 7650 5042 4684 3221 100 1962 100 4638 3187 6413 1377 6432 8013 8013 8013 1403 1920 1828 5307 4415 1353 3216 7309 7579 8024 1920 1828 5307 4415 4638 5031 1908 3221 100 1343 9613 2832 6401 1416 100 8020 1057 857 2496 1921 3221 124 3299 8110 3189 8021 8024 4696 2487 2636 8013 8013 8013 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Writing example 0 of 800\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 2 月 20 日 通 过 携 程 订 的 房 , 结 果 告 之 没 有 普 通 标 房 只 有 行 政 标 间 , 入 住 后 发 现 什 么 行 政 标 间 , 根 本 就 是 普 通 标 房 吗 . 估 计 酒 店 和 携 程 在 打 马 虎 眼 , 298 的 价 格 实 在 不 值 . 后 来 逛 街 看 见 四 星 级 的 漳 州 大 酒 店 , 真 后 悔 没 住 那 儿 只 不 过 贵 100 元 . 还 有 退 房 时 居 然 以 侄 子 流 鼻 血 弄 脏 了 被 子 为 由 要 加 收 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 123 3299 8113 3189 6858 6814 3025 4923 6370 4638 2791 117 5310 3362 1440 722 3766 3300 3249 6858 3403 2791 1372 3300 6121 3124 3403 7313 117 1057 857 1400 1355 4385 784 720 6121 3124 3403 7313 117 3418 3315 2218 3221 3249 6858 3403 2791 1408 119 844 6369 6983 2421 1469 3025 4923 1762 2802 7716 5988 4706 117 10690 4638 817 3419 2141 1762 679 966 119 1400 3341 6859 6125 4692 6224 1724 3215 5277 4638 4040 2336 1920 6983 2421 117 4696 1400 2637 3766 857 6929 1036 1372 679 6814 6586 8135 1039 119 6820 3300 6842 2791 3198 2233 4197 809 888 2094 3837 7965 6117 2462 5552 749 6158 2094 711 4507 6206 1217 3119 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 请 协 成 不 要 再 介 绍 是 准 四 星 未 挂 牌 的 该 酒 店 ， 最 好 不 要 再 与 这 家 酒 店 合 作 ， 有 损 你 们 公 司 声 誉 。 还 不 如 好 的 招 待 所 ， 只 有 表 面 功 夫 ， 位 置 很 吵 ， 旁 边 就 是 公 路 ， 服 务 很 差 ， 整 个 酒 店 很 脏 ， 床 单 ， 枕 套 ， 地 毯 。 。 。 只 能 和 衣 而 睡 ， 半 夜 空 调 变 暖 气 ， 热 死 你 ， 浴 室 脏 ， 不 敢 洗 澡 。 早 餐 无 法 吃 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 6435 1291 2768 679 6206 1086 792 5305 3221 1114 1724 3215 3313 2899 4277 4638 6421 6983 2421 8024 3297 1962 679 6206 1086 680 6821 2157 6983 2421 1394 868 8024 3300 2938 872 812 1062 1385 1898 6289 511 6820 679 1963 1962 4638 2875 2521 2792 8024 1372 3300 6134 7481 1216 1923 8024 855 5390 2523 1427 8024 3178 6804 2218 3221 1062 6662 8024 3302 1218 2523 2345 8024 3146 702 6983 2421 2523 5552 8024 2414 1296 8024 3359 1947 8024 1765 3691 511 511 511 1372 5543 1469 6132 5445 4717 8024 1288 1915 4958 6444 1359 3265 3698 8024 4178 3647 872 8024 3861 2147 5552 8024 679 3140 3819 4074 511 3193 7623 3187 3791 1391 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 很 一 般 的 酒 店 [UNK] [UNK] 性 价 比 一 般 [UNK] [UNK] 酒 店 是 旧 式 房 子 ， 门 感 觉 不 太 安 全 ， 洗 手 间 相 对 来 说 还 算 装 修 的 可 以 ， 只 能 算 宾 馆 ， 不 能 称 作 酒 店 ， 隔 音 很 差 ， 环 境 很 一 般 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2523 671 5663 4638 6983 2421 100 100 2595 817 3683 671 5663 100 100 6983 2421 3221 3191 2466 2791 2094 8024 7305 2697 6230 679 1922 2128 1059 8024 3819 2797 7313 4685 2190 3341 6432 6820 5050 6163 934 4638 1377 809 8024 1372 5543 5050 2161 7667 8024 679 5543 4917 868 6983 2421 8024 7392 7509 2523 2345 8024 4384 1862 2523 671 5663 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 实 在 一 般 ， 这 样 的 酒 店 还 要 这 个 价 钱 ， 令 人 费 解 ！ [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2141 1762 671 5663 8024 6821 3416 4638 6983 2421 6820 6206 6821 702 817 7178 8024 808 782 6589 6237 8013 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: None\n",
      "INFO:tensorflow:tokens: [CLS] 房 间 很 规 整 ， 也 不 像 前 面 网 友 说 的 那 么 隔 音 不 好 ， 我 住 的 是 7 楼 标 [UNK] ， 门 脸 儿 很 小 但 是 都 很 安 静 的 ， 周 边 交 通 很 方 便 ， 打 车 到 虹 桥 只 要 40 多 一 点 ， 20 分 钟 就 能 到 ， 而 且 打 车 到 南 京 西 路 只 要 4 公 里 ， 离 火 车 站 走 路 只 要 10 分 钟 多 点 的 样 子 ， 旁 边 就 是 汽 车 站 ， 交 通 太 方 便 ， 在 上 海 住 很 多 家 旅 店 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2791 7313 2523 6226 3146 8024 738 679 1008 1184 7481 5381 1351 6432 4638 6929 720 7392 7509 679 1962 8024 2769 857 4638 3221 128 3517 3403 100 8024 7305 5567 1036 2523 2207 852 3221 6963 2523 2128 7474 4638 8024 1453 6804 769 6858 2523 3175 912 8024 2802 6756 1168 6004 3441 1372 6206 8164 1914 671 4157 8024 8113 1146 7164 2218 5543 1168 8024 5445 684 2802 6756 1168 1298 776 6205 6662 1372 6206 125 1062 7027 8024 4895 4125 6756 4991 6624 6662 1372 6206 8108 1146 7164 1914 4157 4638 3416 2094 8024 3178 6804 2218 3221 3749 6756 4991 8024 769 6858 1922 3175 912 8024 1762 677 3862 857 2523 1914 2157 3180 2421 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    }
   ],
   "source": [
    "def truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "def convert_single_example(ex_index, example, label_list, max_seq_length,\n",
    "                           tokenizer):\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        return InputFeatures(\n",
    "            input_ids=[0] * max_seq_length,\n",
    "            input_mask=[0] * max_seq_length,\n",
    "            segment_ids=[0] * max_seq_length,\n",
    "            label_id=0,\n",
    "            is_real_example=False)\n",
    "    \n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    tokens_b = None\n",
    "    if example.text_b:\n",
    "        tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "    if tokens_b:\n",
    "        truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "    else:\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\") # 句头添加 [CLS] 标志\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\") # 句尾添加[SEP] 标志\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    if tokens_b:\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)  \n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    label_id = label_map[example.label]\n",
    "    \n",
    "    if ex_index < 5:\n",
    "        tf.logging.info(\"*** 示例 ***\")\n",
    "        tf.logging.info(\"guid: %s\" % (example.guid)) \n",
    "        tf.logging.info(\"tokens: %s\" % \" \".join([tokenization.printable_text(x) for x in tokens])) \n",
    "        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))  \n",
    "        tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask])) \n",
    "        tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids])) \n",
    "        tf.logging.info(\"label: %s (id = %d)\" % (example.label, label_id)) \n",
    "\n",
    "    feature = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_id=label_id,\n",
    "        is_real_example=True)\n",
    "    return feature\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        feature = convert_single_example(ex_index, example, label_list,\n",
    "                                     max_seq_length, tokenizer)\n",
    "\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "train_features = convert_examples_to_features(train_InputExamples, label_list, max_seq_length, tokenizer)\n",
    "test_features = convert_examples_to_features(test_InputExamples, label_list, max_seq_length, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载模型参数，构造模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "\n",
    "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
    "                 labels, num_labels, use_one_hot_embeddings):\n",
    "\n",
    "    model = modeling.BertModel(\n",
    "        config=bert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "    output_layer = model.get_pooled_output()\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if is_training:\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, per_example_loss, logits, probabilities)\n",
    "\n",
    "\n",
    "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps):\n",
    "\n",
    "    def model_fn(features, labels, mode, params):\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "        is_real_example = None\n",
    "        if \"is_real_example\" in features:\n",
    "            is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
    "        else:\n",
    "            is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        use_one_hot_embeddings = False\n",
    "\n",
    "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
    "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
    "            num_labels, use_one_hot_embeddings)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        initialized_variable_names = {}\n",
    "        scaffold_fn = None\n",
    "    \n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names\n",
    "            ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "    \n",
    "            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "        output_spec = None\n",
    "   \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "            train_op = optimization.create_optimizer(\n",
    "              total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "              mode=mode,\n",
    "              loss=total_loss,\n",
    "              train_op=train_op)\n",
    "\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "            def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
    "                predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "                accuracy = tf.metrics.accuracy(\n",
    "                    labels=label_ids, predictions=predictions, weights=is_real_example)\n",
    "                loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"eval_loss\": loss,\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "              mode=mode,\n",
    "              loss=total_loss,\n",
    "              eval_metric_ops=eval_metrics)\n",
    "    \n",
    "        else:\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "              mode=mode,\n",
    "              predictions={\"probabilities\": probabilities})\n",
    "    \n",
    "        return output_spec\n",
    "\n",
    "    return model_fn\n",
    "\n",
    "\n",
    "num_train_steps = int(len(train_features) / batch_size * num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    learning_rate=learning_rate,\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './text_classification/output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff03862add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./text_classification/output/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7224759, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.50949\n",
      "INFO:tensorflow:loss = 0.11819941, step = 100 (66.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.08361\n",
      "INFO:tensorflow:loss = 0.12483026, step = 200 (47.995 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into ./text_classification/output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.037707344.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7ff03862acc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    all_label_ids = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_input_mask.append(feature.input_mask)\n",
    "        all_segment_ids.append(feature.segment_ids)\n",
    "        all_label_ids.append(feature.label_id)\n",
    "\n",
    "    def input_fn(params):\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        num_examples = len(features)\n",
    "\n",
    "        d = tf.data.Dataset.from_tensor_slices({\n",
    "            \"input_ids\":\n",
    "                tf.constant(\n",
    "                    all_input_ids, shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"input_mask\":\n",
    "                tf.constant(\n",
    "                    all_input_mask,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"segment_ids\":\n",
    "                tf.constant(\n",
    "                    all_segment_ids,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"label_ids\":\n",
    "                tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "        })\n",
    "    \n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "        return d\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=save_summary_steps,\n",
    "    save_checkpoints_steps=save_checkpoints_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    params={\"batch_size\": batch_size})\n",
    "\n",
    "train_input_fn = input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=True,\n",
    "    drop_remainder=False) \n",
    "\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在测试集上测试，评估测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-11-10:15:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./text_classification/output/model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-11-10:15:33\n",
      "INFO:tensorflow:Saving dict for global step 300: eval_accuracy = 0.895, eval_loss = 0.37930623, global_step = 300, loss = 0.37930623\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: ./text_classification/output/model.ckpt-300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "打印测试评估指标\n",
      "eval_accuracy : 0.895\n",
      "eval_loss : 0.37930623\n",
      "loss : 0.37930623\n",
      "global_step : 300\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "evaluate_info = estimator.evaluate(input_fn=eval_input_fn, steps=None)\n",
    "\n",
    "print(\"\\n打印测试评估指标\")\n",
    "for key in evaluate_info:\n",
    "    print(key+' : '+str(evaluate_info[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在线测试\n",
    "\n",
    "由以上训练得到模型进行在线测试，可以任意输入句子，进行文本情感分析。\n",
    "\n",
    "输入“再见”，结束在线文本情感分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在线文本情感分析:\n",
      "\n",
      "前台的服务态度非常好\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: \n",
      "INFO:tensorflow:tokens: [CLS] 前 台 的 服 务 态 度 非 常 好 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1184 1378 4638 3302 1218 2578 2428 7478 2382 1962 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./text_classification/output/model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "评论： 前台的服务态度非常好\n",
      "得分： [0.00234603 0.997654  ]\n",
      "评论情感分析： 正面评价\n",
      "房间外的风景很好\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: \n",
      "INFO:tensorflow:tokens: [CLS] 房 间 外 的 风 景 很 好 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2791 7313 1912 4638 7599 3250 2523 1962 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./text_classification/output/model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "评论： 房间外的风景很好\n",
      "得分： [0.00231626 0.99768376]\n",
      "评论情感分析： 正面评价\n",
      "房间很脏，没有打扫\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1\n",
      "INFO:tensorflow:*** 示例 ***\n",
      "INFO:tensorflow:guid: \n",
      "INFO:tensorflow:tokens: [CLS] 房 间 很 脏 ， 没 有 打 扫 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2791 7313 2523 5552 8024 3766 3300 2802 2812 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./text_classification/output/model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "评论： 房间很脏，没有打扫\n",
      "得分： [0.99627495 0.00372511]\n",
      "评论情感分析： 负面评价\n",
      "再见\n",
      "\n",
      "再见\n"
     ]
    }
   ],
   "source": [
    "def getPrediction(in_sentences):\n",
    "    labels = [\"负面评价\", \"正面评价\"]\n",
    "    input_examples = [InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "    input_features = convert_examples_to_features(input_examples, label_list, max_seq_length, tokenizer)\n",
    "    predict_input_fn = input_fn_builder(features=input_features, seq_length=max_seq_length, is_training=False, drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    for sentence, prediction in zip(in_sentences, predictions):\n",
    "        print(\"\\n评论：\", sentence)\n",
    "        print(\"得分：\", prediction['probabilities'])\n",
    "        print(\"评论情感分析：\", labels[int(round(prediction['probabilities'][1]))])\n",
    "    return \n",
    "\n",
    "def sentiment_analysis():\n",
    "    while True:\n",
    "        pred_sentences = [input()]\n",
    "        if pred_sentences == [\"再见\"]:\n",
    "            print(\"\\n再见\")\n",
    "            return\n",
    "        else:\n",
    "            predictions = getPrediction(pred_sentences)\n",
    "\n",
    "print(\"在线文本情感分析:\\n\")            \n",
    "sentiment_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
